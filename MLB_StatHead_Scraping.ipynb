{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f51d979c",
   "metadata": {},
   "source": [
    "# Part 1: Data Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0562012",
   "metadata": {},
   "source": [
    "## Selenium for Pitching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2967a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import codecs\n",
    "import re\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from io import StringIO\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ignore warnings\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae93e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start webdriver\n",
    "driver = webdriver.Chrome(executable_path=\"C:\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automate login\n",
    "driver.get('https://stathead.com/users/login.cgi')\n",
    "username = None\n",
    "password = None\n",
    "driver.find_element(By.ID, 'username').send_keys(username)\n",
    "driver.find_element(By.ID, 'password').send_keys(password)\n",
    "driver.find_element(By.XPATH, '//*[@id=\"sh-login-button\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59c6d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GET DATA\n",
    "frames = []\n",
    "df_number = 0\n",
    "for offset in range(0, 211000, 200):\n",
    "    df_number += 1\n",
    "    print('getting dataframe', str(df_number), 'of', str(211000/200), '(offset =', str(offset) + ')')\n",
    "    \n",
    "    # use plitcher game stat finder url to get data\n",
    "    request_url = 'https://stathead.com/baseball/player-pitching-game-finder.cgi?request=1&is_pitcher=1&team_game_min=1&comp_type=reg&order_by=date&player_game_max=9999&team_game_max=165&order_by_asc=0&locationMatch=is&days_rest_comp==&year_min=2012&player_game_min=1&max_wind_speed=90&location=pob&max_temperature=120&match=player_game&year_max=2022&min_temperature=0&min_wind_speed=0&role=anyGS&offset=' + str(offset)\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    driver.get(request_url)\n",
    "    get_url = driver.current_url\n",
    "    wait.until(EC.url_to_be(request_url))\n",
    "    \n",
    "    # create ActionChains object\n",
    "    a = ActionChains(driver)\n",
    "    \n",
    "    # find export button\n",
    "    m = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"stats_sh\"]/div/ul/li[1]/span')))\n",
    "    \n",
    "    # click export data button\n",
    "    a.move_to_element(m).perform()\n",
    "    \n",
    "    # click export to CSV button\n",
    "    n = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, '//button[text()=\"Get table as CSV (for Excel)\"]')))\n",
    "    n.click()\n",
    "    \n",
    "    # get page source for BS4 to parse\n",
    "    if get_url == request_url:\n",
    "        page_source = driver.page_source\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(page_source,features='html.parser')\n",
    "    \n",
    "    # get csv formatted table from page\n",
    "    t_text = soup.find('pre', {\"id\": \"csv_stats\"}).getText()[80:]\n",
    "    \n",
    "    # create dataframe with table\n",
    "    csv_df = pd.read_csv(StringIO(t_text), sep=\",\")\n",
    "\n",
    "    # append csv_df to frames\n",
    "    frames.append(csv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead9383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitcher_df_all = pd.concat(frames)\n",
    "\n",
    "pitcher_df_all = pitcher_df_all.reset_index(drop = True)\n",
    "\n",
    "pitcher_df_all.to_csv('pitcher_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8eaa52",
   "metadata": {},
   "source": [
    "## Selenium for Batting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17866c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import codecs\n",
    "import re\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from io import StringIO\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ignore warnings\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb91e2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# start webdriver\n",
    "driver = webdriver.Chrome(executable_path=\"C:\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcef897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automate login\n",
    "driver.get('https://stathead.com/users/login.cgi')\n",
    "username = None\n",
    "password = None\n",
    "driver.find_element(By.ID, 'username').send_keys(username)\n",
    "driver.find_element(By.ID, 'password').send_keys(password)\n",
    "driver.find_element(By.XPATH, '//*[@id=\"sh-login-button\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6207dd45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GET DATA\n",
    "frames = []\n",
    "df_number = 0\n",
    "for offset in range(0, 732400, 200):\n",
    "    df_number += 1\n",
    "    print('getting dataframe', str(df_number), 'of', str(732400/200), '(offset =', str(offset) + ')')\n",
    "    \n",
    "    # use batter game stat finder url to get data\n",
    "    request_url = 'https://stathead.com/baseball/player-batting-game-finder.cgi?request=1&team_game_min=1&comp_type=reg&order_by=date&player_game_max=9999&team_game_max=165&order_by_asc=0&locationMatch=is&year_min=2012&player_game_min=1&GF=anyGF&max_wind_speed=90&location=pob&max_temperature=120&match=player_game&year_max=2022&min_temperature=0&exactness=anymarked&min_wind_speed=0&offset=' + str(offset)\n",
    "    wait = WebDriverWait(driver, 100)\n",
    "    driver.get(request_url)\n",
    "    get_url = driver.current_url\n",
    "    wait.until(EC.url_to_be(request_url))\n",
    "    \n",
    "    # create ActionChains object\n",
    "    a = ActionChains(driver)\n",
    "    \n",
    "    # find export button\n",
    "    m = WebDriverWait(driver, 100).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"stats_sh\"]/div/ul/li[1]/span')))\n",
    "    \n",
    "    # click export data button\n",
    "    a.move_to_element(m).perform()\n",
    "    \n",
    "    # click export to CSV button\n",
    "    n = WebDriverWait(driver, 100).until(EC.element_to_be_clickable((By.XPATH, '//button[text()=\"Get table as CSV (for Excel)\"]')))\n",
    "    n.click()\n",
    "    \n",
    "    # get page source for BS4 to parse\n",
    "    if get_url == request_url:\n",
    "        page_source = driver.page_source\n",
    "    \n",
    "    # get soup\n",
    "    soup = BeautifulSoup(page_source,features='html.parser')\n",
    "    \n",
    "    # get csv formatted table from page\n",
    "    t_text = soup.find('pre', {\"id\": \"csv_stats\"}).getText()[80:]\n",
    "    \n",
    "    # create dataframe with table\n",
    "    csv_df = pd.read_csv(StringIO(t_text), sep=\",\")\n",
    "\n",
    "    # append csv_df to frames\n",
    "    frames.append(csv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2596e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batter_df_all = pd.concat(frames)\n",
    "\n",
    "batter_df_all.tail()\n",
    "\n",
    "batter_df_all = batter_df_all.reset_index(drop = True)\n",
    "\n",
    "batter_df_all.to_csv('batter_stats.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
